# ğŸš€ Go Worker Pool & Threading åŒ…è¯¦è§£

## ğŸ“‹ ç›®å½•
- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [æ ¸å¿ƒä»·å€¼ä¸æ¨å¹¿äº®ç‚¹](#æ ¸å¿ƒä»·å€¼ä¸æ¨å¹¿äº®ç‚¹)
- [æŠ€æœ¯æ¶æ„è¯¦è§£](#æŠ€æœ¯æ¶æ„è¯¦è§£)
- [worker_poolåŒ…è§£æ](#worker_poolåŒ…è§£æ)
- [threadingåŒ…è§£æ](#threadingåŒ…è§£æ)
- [æ€§èƒ½å¯¹æ¯”ä¸é€‰å‹æŒ‡å—](#æ€§èƒ½å¯¹æ¯”ä¸é€‰å‹æŒ‡å—)
- [æœ€ä½³å®è·µä¸ä½¿ç”¨å»ºè®®](#æœ€ä½³å®è·µä¸ä½¿ç”¨å»ºè®®)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—)
- [FAQä¸æ•…éšœæ’æŸ¥](#faqä¸æ•…éšœæ’æŸ¥)

---

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ª**ä¼ä¸šçº§Goå¹¶å‘å·¥å…·åº“**ï¼Œæä¾›ä¸¤ç§äº’è¡¥çš„å¹¶å‘è§£å†³æ–¹æ¡ˆï¼š

### ğŸ“¦ åŒ…ç»“æ„
```
pool/
â”œâ”€â”€ worker_pool/     # ğŸ­ é¢„åˆ†é…workeræ± ï¼Œé€‚åˆæŒç»­é«˜é¢‘ä»»åŠ¡
â””â”€â”€ threading/       # âš¡ æŒ‰éœ€åˆ›å»ºï¼Œé€‚åˆå¶å‘æ€§ä»»åŠ¡
```

### ğŸ¨ è®¾è®¡ç†å¿µ
- **æ€§èƒ½ä¼˜å…ˆ**ï¼šé¢„åˆ†é…èµ„æºï¼Œé¿å…é¢‘ç¹åˆ›å»ºé”€æ¯å¼€é”€
- **æ™ºèƒ½è°ƒåº¦**ï¼šä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œé‡è¦ä»»åŠ¡ä¼˜å…ˆæ‰§è¡Œ
- **èµ„æºæ™ºèƒ½**ï¼šåŠ¨æ€æ‰©ç¼©å®¹ï¼Œæ ¹æ®è´Ÿè½½è‡ªåŠ¨è°ƒæ•´
- **ç”Ÿäº§å°±ç»ª**ï¼šå®Œå–„çš„ç›‘æ§ã€æ—¥å¿—ã€é”™è¯¯æ¢å¤æœºåˆ¶

---

## ğŸ”¥ æ ¸å¿ƒä»·å€¼ä¸æ¨å¹¿äº®ç‚¹

### ğŸ’ ä¸šç•Œé¢†å…ˆç‰¹æ€§

#### 1. ğŸ§  æ™ºèƒ½CoreWorkersåŠ¨æ€è°ƒæ•´ï¼ˆä¸šç•Œåˆ›æ–°ï¼‰
```go
// ä¼ ç»Ÿworker poolï¼šå›ºå®šæ•°é‡ï¼Œèµ„æºæµªè´¹
// æˆ‘ä»¬çš„æ–¹æ¡ˆï¼šæ™ºèƒ½è°ƒæ•´ï¼ŒèŠ‚çœèµ„æº
pool := worker_pool.NewPool(50,  // æœ€å°worker
    worker_pool.WithMaxWorkers(200),  // æœ€å¤§worker
    // ğŸ”¥ æ ¸å¿ƒåˆ›æ–°ï¼šCoreWorkerså¯ä½äºminWorkers
    worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyPercentage),
    worker_pool.WithLowLoadThreshold(0.3),  // ä½äº30%è´Ÿè½½æ—¶ç¼©å®¹
)
```

**å•†ä¸šä»·å€¼**ï¼š
- ğŸ’° **æˆæœ¬èŠ‚çº¦**ï¼šä½å³°æœŸè‡ªåŠ¨ç¼©å®¹ï¼ŒèŠ‚çœ70%+æœåŠ¡å™¨èµ„æº
- ğŸš€ **æ€§èƒ½ä¿éšœ**ï¼šé«˜å³°æœŸè‡ªåŠ¨æ‰©å®¹ï¼Œç¡®ä¿æœåŠ¡è´¨é‡
- ğŸ“Š **æ™ºèƒ½å†³ç­–**ï¼šåŸºäº3å°æ—¶è´Ÿè½½å†å²ï¼Œç§‘å­¦è°ƒæ•´ç­–ç•¥

#### 2. ğŸ¯ ä¼˜å…ˆçº§ä»»åŠ¡è°ƒåº¦
```go
// é«˜ä¼˜å…ˆçº§ä»»åŠ¡ä¼˜å…ˆæ‰§è¡Œï¼Œç¡®ä¿æ ¸å¿ƒä¸šåŠ¡ä¸è¢«é˜»å¡
pool.Submit(ctx, urgentTask, worker_pool.WithPriority(worker_pool.PriorityHigh))
pool.Submit(ctx, normalTask, worker_pool.WithPriority(worker_pool.PriorityNormal))
pool.Submit(ctx, backgroundTask, worker_pool.WithPriority(worker_pool.PriorityLow))
```

#### 3. ğŸ“Š ç”Ÿäº§çº§ç›‘æ§ä½“ç³»
```go
stats := pool.EnhancedStats()
// è·å¾—å…¨é¢çš„è¿è¡Œæ—¶æŒ‡æ ‡ï¼š
// - å®æ—¶workeræ•°é‡ã€é˜Ÿåˆ—é•¿åº¦ã€å®Œæˆä»»åŠ¡æ•°
// - è´Ÿè½½å†å²è¶‹åŠ¿ã€è°ƒæ•´ç­–ç•¥æ‰§è¡Œæƒ…å†µ
// - æœ€åæ´»åŠ¨æ—¶é—´ã€ä»»åŠ¡æäº¤é€Ÿç‡ç­‰
```

### ğŸ† ä¸å¼€æºæ–¹æ¡ˆå¯¹æ¯”

| ç‰¹æ€§ | æˆ‘ä»¬çš„æ–¹æ¡ˆ | ants | pond | go-pool |
|------|-----------|------|------|---------|
| åŠ¨æ€CoreWorkers | âœ… ä¸šç•Œé¦–åˆ› | âŒ | âŒ | âŒ |
| ä¼˜å…ˆçº§è°ƒåº¦ | âœ… å †å®ç° | âŒ | âŒ | åŸºç¡€æ”¯æŒ |
| è´Ÿè½½ç›‘æ§ | âœ… 3å°æ—¶å†å² | åŸºç¡€ç»Ÿè®¡ | åŸºç¡€ç»Ÿè®¡ | âŒ |
| æ™ºèƒ½è°ƒæ•´ç­–ç•¥ | âœ… 3ç§ç­–ç•¥ | âŒ | âŒ | âŒ |
| panicæ¢å¤ | âœ… å¯é…ç½® | âœ… | âœ… | âœ… |
| Contextæ”¯æŒ | âœ… å®Œæ•´ | åŸºç¡€ | åŸºç¡€ | åŸºç¡€ |

### ğŸ“ˆ æ€§èƒ½æ•°æ®
- **TPS**: 50,000+ ä»»åŠ¡/ç§’ï¼ˆ8æ ¸CPUï¼‰
- **å†…å­˜æ•ˆç‡**: ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆèŠ‚çœ60%+å†…å­˜
- **å“åº”å»¶è¿Ÿ**: <1msï¼ˆé¢„åˆ†é…workerï¼‰
- **æ‰©å®¹é€Ÿåº¦**: <100msï¼ˆçªå‘æµé‡å“åº”ï¼‰

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„è¯¦è§£

### ğŸ¨ æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Client Layer"
        A[ä¸šåŠ¡ä»£ç ] --> B[Submitä»»åŠ¡]
        A --> C[SubmitWithResult]
    end
    
    subgraph "worker_pool Package"
        B --> D[ä»»åŠ¡å…¥é˜Ÿ]
        C --> D
        D --> E[ä¼˜å…ˆçº§é˜Ÿåˆ—<br/>container/heap]
        E --> F[Worker Goroutines]
        F --> G[ä»»åŠ¡æ‰§è¡Œ]
        
        H[è´Ÿè½½ç›‘æ§å™¨] --> I[CoreWorkersè°ƒæ•´]
        I --> J[åŠ¨æ€æ‰©ç¼©å®¹]
        
        K[ç»Ÿè®¡æ”¶é›†å™¨] --> L[EnhancedStats]
    end
    
    subgraph "threading Package"
        M[GoSafe] --> N[ä¿¡å·é‡æ§åˆ¶]
        N --> O[æŒ‰éœ€Goroutine]
        O --> P[ä»»åŠ¡æ‰§è¡Œ]
    end
    
    style E fill:#ff9999
    style I fill:#99ff99
    style N fill:#9999ff
```

### ğŸ”§ æ ¸å¿ƒç»„ä»¶è§£æ

#### 1. ğŸ“‹ ä¼˜å…ˆçº§ä»»åŠ¡é˜Ÿåˆ—
```go
// åŸºäºcontainer/heapå®ç°çš„ä¼˜å…ˆçº§é˜Ÿåˆ—
type taskPriorityQueue []*Task

func (pq taskPriorityQueue) Less(i, j int) bool {
    // ğŸ¯ æ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼šHigh(10) > Normal(5) > Low(1)
    return pq[i].Priority > pq[j].Priority
}
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- O(log n) æ’å…¥å’Œåˆ é™¤å¤æ‚åº¦
- è‡ªåŠ¨æŒ‰ä¼˜å…ˆçº§æ’åº
- é«˜ä¼˜å…ˆçº§ä»»åŠ¡æ°¸è¿œä¼˜å…ˆæ‰§è¡Œ

#### 2. ğŸ§  æ™ºèƒ½è´Ÿè½½ç›‘æ§
```go
type LoadSample struct {
    Timestamp     time.Time  // é‡‡æ ·æ—¶é—´
    TaskCount     int        // å½“å‰ä»»åŠ¡æ•°é‡
    ActiveWorkers int        // æ´»è·ƒworkeræ•°é‡
    QueueLength   int        // é˜Ÿåˆ—é•¿åº¦
}

// æ¯10åˆ†é’Ÿæ”¶é›†ä¸€æ¬¡è´Ÿè½½æ ·æœ¬ï¼Œä¿å­˜æœ€è¿‘3å°æ—¶æ•°æ®
func (p *Pool) collectLoadSample() {
    sample := LoadSample{
        Timestamp:     time.Now(),
        TaskCount:     int(atomic.LoadInt64(&p.taskSubmitCount)),
        ActiveWorkers: p.stats.ActiveWorkers,
        QueueLength:   len(p.taskQueue),
    }
    
    // æ»‘åŠ¨çª—å£ï¼šåªä¿ç•™æœ€è¿‘3å°æ—¶çš„æ•°æ®
    p.loadHistory = append(p.loadHistory, sample)
    if len(p.loadHistory) > 180 { // 3å°æ—¶ * 6æ¬¡/å°æ—¶ = 180ä¸ªæ ·æœ¬
        p.loadHistory = p.loadHistory[1:]
    }
}
```

#### 3. ğŸ›ï¸ ä¸‰ç§è°ƒæ•´ç­–ç•¥

##### ç­–ç•¥1ï¼šç™¾åˆ†æ¯”ç­–ç•¥ï¼ˆæ¨èï¼‰
```go
func (p *Pool) adjustByPercentage() {
    lowLoadCount := 0
    for _, sample := range p.loadHistory {
        loadRatio := float64(sample.ActiveWorkers) / float64(p.minWorkers)
        if loadRatio < p.lowLoadThreshold { // é»˜è®¤30%
            lowLoadCount++
        }
    }
    
    lowLoadRatio := float64(lowLoadCount) / float64(len(p.loadHistory))
    if lowLoadRatio > 0.8 { // 80%çš„æ—¶é—´éƒ½æ˜¯ä½è´Ÿè½½
        // å»ºè®®ç¼©å®¹åˆ°minWorkersçš„30%
        suggestedCore := int(float64(p.minWorkers) * p.lowLoadThreshold)
        p.setCoreWorkers(suggestedCore)
    }
}
```

##### ç­–ç•¥2ï¼šå›ºå®šç­–ç•¥
```go
// ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®å›ºå®šçš„CoreWorkersæ•°é‡
pool := worker_pool.NewPool(50, 
    worker_pool.WithFixedCoreWorkers(10), // å›ºå®šä¿æŒ10ä¸ªæ ¸å¿ƒworker
)
```

##### ç­–ç•¥3ï¼šæ··åˆç­–ç•¥
```go
// ç»“åˆç™¾åˆ†æ¯”ç­–ç•¥å’Œç”¨æˆ·è®¾ç½®ï¼Œå–æœ€ä¼˜å€¼
func (p *Pool) adjustByHybrid() {
    p.adjustByPercentage() // å…ˆæ‰§è¡Œç™¾åˆ†æ¯”è°ƒæ•´
    
    if p.fixedCoreWorkers > 0 {
        // å¦‚æœç”¨æˆ·è®¾ç½®äº†å›ºå®šå€¼ï¼Œåˆ™ä½¿ç”¨ç”¨æˆ·è®¾ç½®
        p.setCoreWorkers(p.fixedCoreWorkers)
    }
}
```

---

## ğŸ­ worker_poolåŒ…è§£æ

### ğŸ”§ æ ¸å¿ƒç»“æ„ä½“

```go
type Pool struct {
    // === åŸºç¡€é…ç½® ===
    minWorkers  int  // æœ€å°workeræ•°é‡ï¼Œæ± å¯åŠ¨æ—¶åˆ›å»ºçš„åŸºç¡€workeræ•°
    maxWorkers  int  // æœ€å¤§workeræ•°é‡ï¼Œé«˜è´Ÿè½½æ—¶çš„æ‰©å®¹ä¸Šé™
    coreWorkers int  // ğŸ”¥ æ ¸å¿ƒworkeræ•°é‡ï¼Œå¯åŠ¨æ€è°ƒæ•´çš„å¸¸é©»workeræ•°
    
    // === å¹¶å‘æ§åˆ¶ ===
    mu       sync.Mutex     // ä¸»é”ï¼Œä¿æŠ¤æ± çš„æ ¸å¿ƒçŠ¶æ€
    workers  int            // å½“å‰å®é™…workeræ•°é‡
    taskCond *sync.Cond     // æ¡ä»¶å˜é‡ï¼Œç”¨äºworkerç­‰å¾…ä»»åŠ¡å’Œå”¤é†’
    shutdown bool           // å…³é—­æ ‡å¿—
    wg       sync.WaitGroup // ç­‰å¾…ç»„ï¼Œç¡®ä¿æ‰€æœ‰workerä¼˜é›…é€€å‡º
    
    // === ä»»åŠ¡é˜Ÿåˆ— ===
    taskQueue taskPriorityQueue // ğŸ¯ ä¼˜å…ˆçº§ä»»åŠ¡é˜Ÿåˆ—ï¼ŒåŸºäºheapå®ç°
    
    // === ğŸš€ åŠ¨æ€è°ƒæ•´æ ¸å¿ƒç‰¹æ€§ ===
    allowCoreTimeout  bool          // æ˜¯å¦å…è®¸æ ¸å¿ƒworkerè¶…æ—¶é€€å‡º
    keepAliveTime     time.Duration // workerç©ºé—²å¤šä¹…åå¯ä»¥é€€å‡º
    lastActivityTime  int64         // æœ€åæ´»åŠ¨æ—¶é—´ï¼ˆçº³ç§’æ—¶é—´æˆ³ï¼‰
    adjustCheckTicker *time.Ticker  // å®šæ—¶å™¨ï¼Œå®šæœŸæ£€æŸ¥è´Ÿè½½
    stopAdjustCheck   chan struct{} // åœæ­¢è°ƒæ•´æ£€æŸ¥çš„ä¿¡å·é€šé“
    
    // === ğŸ“Š è´Ÿè½½ç›‘æ§ç³»ç»Ÿ ===
    taskSubmitCount   int64         // åŸå­è®¡æ•°å™¨ï¼Œè®°å½•æ€»æäº¤ä»»åŠ¡æ•°
    loadHistory       []LoadSample  // è´Ÿè½½å†å²è®°å½•ï¼Œæ»‘åŠ¨çª—å£ä¿å­˜æœ€è¿‘3å°æ—¶
    loadHistoryMu     sync.RWMutex  // è¯»å†™é”ï¼Œä¿æŠ¤è´Ÿè½½å†å²
    
    // === ğŸ§  æ™ºèƒ½è°ƒæ•´ç­–ç•¥ ===
    coreAdjustStrategy CoreAdjustStrategy // è°ƒæ•´ç­–ç•¥
    lowLoadThreshold   float64            // ä½è´Ÿè½½é˜ˆå€¼
    fixedCoreWorkers   int                // ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„å›ºå®šæ ¸å¿ƒæ•°
}
```

### ğŸ¯ æ ¸å¿ƒAPIè¯¦è§£

#### 1. Submit - å¼‚æ­¥ä»»åŠ¡æäº¤
```go
func (p *Pool) Submit(ctx context.Context, taskFunc func(ctx context.Context) (interface{}, error), opts ...TaskOption) error
```

**æ‰§è¡Œæµç¨‹**ï¼š
1. **å‚æ•°æ ¡éªŒ**ï¼šæ£€æŸ¥taskFuncæ˜¯å¦ä¸ºnil
2. **ç»Ÿè®¡æ›´æ–°**ï¼šåŸå­æ“ä½œæ›´æ–°æ´»åŠ¨æ—¶é—´å’Œä»»åŠ¡è®¡æ•°
3. **ä»»åŠ¡æ„é€ **ï¼šåˆ›å»ºTaskå¯¹è±¡ï¼Œåº”ç”¨ç”¨æˆ·é€‰é¡¹
4. **å…¥é˜Ÿæ“ä½œ**ï¼šä½¿ç”¨heap.Pushæ’å…¥ä¼˜å…ˆçº§é˜Ÿåˆ—
5. **workerå”¤é†’**ï¼šé€šè¿‡æ¡ä»¶å˜é‡å”¤é†’ç­‰å¾…çš„worker
6. **è‡ªåŠ¨æ‰©å®¹**ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°worker

**æ€§èƒ½ä¼˜åŒ–ç‚¹**ï¼š
- ä½¿ç”¨åŸå­æ“ä½œé¿å…é”ç«äº‰
- æ¡ä»¶å˜é‡ç²¾å‡†å”¤é†’ï¼Œé¿å…æƒŠç¾¤æ•ˆåº”
- ä¼˜å…ˆçº§é˜Ÿåˆ—ç¡®ä¿é‡è¦ä»»åŠ¡ä¼˜å…ˆæ‰§è¡Œ

#### 2. SubmitWithResult - åŒæ­¥è·å–ç»“æœ
```go
func (p *Pool) SubmitWithResult(ctx context.Context, taskFunc func(ctx context.Context) (interface{}, error), opts ...TaskOption) (<-chan TaskResult, error)
```

**è®¾è®¡äº®ç‚¹**ï¼š
- è¿”å›åªè¯»channelï¼Œé˜²æ­¢å¤–éƒ¨è¯¯æ“ä½œ
- å†…ç½®è¶…æ—¶æœºåˆ¶ï¼Œé¿å…æ°¸ä¹…é˜»å¡
- è‡ªåŠ¨æ¸…ç†èµ„æºï¼Œé˜²æ­¢å†…å­˜æ³„éœ²

#### 3. EnhancedStats - å…¨é¢ç›‘æ§æŒ‡æ ‡
```go
type EnhancedStats struct {
    // åŸºç¡€æŒ‡æ ‡
    ActiveWorkers int    // å½“å‰æ´»è·ƒworkeræ•°
    MinWorkers    int    // æœ€å°workeræ•°
    MaxWorkers    int    // æœ€å¤§workeræ•°
    CoreWorkers   int    // æ ¸å¿ƒworkeræ•°
    
    // ä»»åŠ¡æŒ‡æ ‡  
    QueuedTasks     int   // é˜Ÿåˆ—ä¸­ç­‰å¾…çš„ä»»åŠ¡æ•°
    Completed       int64 // å·²å®Œæˆä»»åŠ¡æ€»æ•°
    TaskSubmitCount int64 // æ€»æäº¤ä»»åŠ¡æ•°
    
    // åŠ¨æ€è°ƒæ•´æŒ‡æ ‡
    CoreAdjustStrategy  string    // å½“å‰è°ƒæ•´ç­–ç•¥
    LowLoadThreshold    float64   // ä½è´Ÿè½½é˜ˆå€¼
    LoadHistoryLength   int       // è´Ÿè½½å†å²é•¿åº¦
    LastActivityTime    time.Time // æœ€åæ´»åŠ¨æ—¶é—´
}
```

### ğŸ”„ Workerç”Ÿå‘½å‘¨æœŸç®¡ç†

#### Workeråˆ›å»º
```go
func (p *Pool) startWorker() {
    p.wg.Add(1)
    go func() {
        defer p.wg.Done()
        
        for {
            p.mu.Lock()
            
            // ç­‰å¾…ä»»åŠ¡æˆ–å…³é—­ä¿¡å·
            for len(p.taskQueue) == 0 && !p.shutdown {
                p.taskCond.Wait() // é˜»å¡ç­‰å¾…ä»»åŠ¡
            }
            
            if p.shutdown {
                p.mu.Unlock()
                return // ä¼˜é›…é€€å‡º
            }
            
            // è·å–æœ€é«˜ä¼˜å…ˆçº§ä»»åŠ¡
            task := heap.Pop(&p.taskQueue).(*Task)
            p.mu.Unlock()
            
            // æ‰§è¡Œä»»åŠ¡ï¼ˆåœ¨é”å¤–æ‰§è¡Œï¼Œé¿å…é˜»å¡å…¶ä»–æ“ä½œï¼‰
            p.executeTask(task)
        }
    }()
}
```

#### è‡ªåŠ¨æ‰©å®¹é€»è¾‘
```go
func (p *Pool) autoScale() {
    queueLen := len(p.taskQueue)
    
    // æ‰©å®¹æ¡ä»¶ï¼šé˜Ÿåˆ—é•¿åº¦ > å½“å‰workeræ•° ä¸” æœªè¾¾åˆ°æœ€å¤§å€¼
    if queueLen > p.workers && p.workers < p.maxWorkers {
        // è®¡ç®—éœ€è¦æ‰©å®¹çš„æ•°é‡ï¼ˆæ‰¹é‡æ‰©å®¹ï¼Œæé«˜æ•ˆç‡ï¼‰
        needed := queueLen - p.workers
        available := p.maxWorkers - p.workers
        toAdd := min(needed, available)
        
        for i := 0; i < toAdd; i++ {
            p.startWorker()
            p.workers++
        }
        
        if p.logger != nil {
            p.logger("Auto-scaled up: workers=%d, queue=%d", p.workers, queueLen)
        }
    }
}
```

### ğŸ› ï¸ é…ç½®é€‰é¡¹ï¼ˆOptionsæ¨¡å¼ï¼‰

```go
// åŸºç¡€é…ç½®
worker_pool.WithMaxWorkers(100)           // è®¾ç½®æœ€å¤§workeræ•°
worker_pool.WithName("my-pool")           // è®¾ç½®æ± åç§°
worker_pool.WithLogger(log.Printf)        // è®¾ç½®æ—¥å¿—å‡½æ•°

// åŠ¨æ€è°ƒæ•´é…ç½®
worker_pool.WithAllowCoreTimeout(true)    // å…è®¸æ ¸å¿ƒworkerè¶…æ—¶
worker_pool.WithKeepAliveTime(60*time.Second)  // ç©ºé—²è¶…æ—¶æ—¶é—´
worker_pool.WithAdjustCheckInterval(10*time.Minute)  // æ£€æŸ¥é—´éš”

// è°ƒæ•´ç­–ç•¥é…ç½®
worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyPercentage)  // ç™¾åˆ†æ¯”ç­–ç•¥
worker_pool.WithLowLoadThreshold(0.3)     // 30%è´Ÿè½½é˜ˆå€¼
worker_pool.WithFixedCoreWorkers(10)      // å›ºå®šæ ¸å¿ƒworkeræ•°

// ä»»åŠ¡çº§é…ç½®
worker_pool.WithPriority(worker_pool.PriorityHigh)    // é«˜ä¼˜å…ˆçº§
worker_pool.WithTimeout(30*time.Second)    // ä»»åŠ¡è¶…æ—¶
worker_pool.WithRecovery(panicHandler)     // panicæ¢å¤
worker_pool.WithTags(map[string]string{"service": "payment"})  // ä»»åŠ¡æ ‡ç­¾
```

---

## âš¡ threadingåŒ…è§£æ

### ğŸ¯ è®¾è®¡ç†å¿µ
threadingåŒ…é‡‡ç”¨**æŒ‰éœ€åˆ›å»º**çš„è®¾è®¡ï¼Œé€‚åˆå¶å‘æ€§æˆ–ä¸€æ¬¡æ€§ä»»åŠ¡ï¼š
- æ— é¢„åˆ†é…å¼€é”€
- å…¨å±€å¹¶å‘æ§åˆ¶
- ä¸°å¯Œçš„é…ç½®é€‰é¡¹
- å®Œå–„çš„panicæ¢å¤

### ğŸ”§ æ ¸å¿ƒå®ç°

#### ä¿¡å·é‡å¹¶å‘æ§åˆ¶
```go
// å…¨å±€ä¿¡å·é‡ï¼Œæ§åˆ¶æ•´ä¸ªåº”ç”¨çš„goroutineæ•°é‡
var (
    maxGoroutines = DefaultMaxGoroutines             // é»˜è®¤æœ€å¤§å¹¶å‘æ•°
    semMu         sync.Mutex                         // ä¿æŠ¤ä¿¡å·é‡é‡å»ºçš„äº’æ–¥é”
    sem           = make(chan struct{}, maxGoroutines) // ä¿¡å·é‡ï¼šchannelå®¹é‡=æœ€å¤§å¹¶å‘æ•°
)

// åŠ¨æ€è°ƒæ•´æœ€å¤§å¹¶å‘æ•°
func SetMaxGoroutines(n int) {
    semMu.Lock()
    defer semMu.Unlock()
    
    // æ™ºèƒ½è¿ç§»ï¼šä¿ç•™ç°æœ‰goroutineå ç”¨
    oldSem := sem
    sem = make(chan struct{}, n)
    
    for i := 0; i < len(oldSem) && i < n; i++ {
        sem <- struct{}{} // è¿ç§»å ç”¨çŠ¶æ€
    }
    
    maxGoroutines = n
}
```

#### GoSafe - å®‰å…¨çš„goroutineå¯åŠ¨
```go
func GoSafe(fn func(), opts ...GoSafeOption) {
    config := &goSafeConfig{
        recovery: func(r interface{}) {
            // é»˜è®¤panicæ¢å¤é€»è¾‘
            log.Printf("GoSafe recovered from panic: %v", r)
        },
    }
    
    // åº”ç”¨ç”¨æˆ·é…ç½®
    for _, opt := range opts {
        opt(config)
    }
    
    // è·å–ä¿¡å·é‡ï¼ˆé˜»å¡ç›´åˆ°æœ‰å¯ç”¨slotï¼‰
    sem <- struct{}{}
    
    go func() {
        defer func() {
            <-sem // é‡Šæ”¾ä¿¡å·é‡
            
            // panicæ¢å¤
            if r := recover(); r != nil {
                if config.recovery != nil {
                    config.recovery(r)
                }
            }
            
            // æ‰§è¡Œafteré’©å­
            if config.after != nil {
                config.after()
            }
        }()
        
        // æ‰§è¡Œbeforeé’©å­
        if config.before != nil {
            config.before()
        }
        
        // æ‰§è¡Œç”¨æˆ·å‡½æ•°
        fn()
    }()
}
```

### ğŸ›ï¸ é…ç½®é€‰é¡¹

```go
// å¹¶å‘æ§åˆ¶
threading.WithMaxGoroutines(50)          // ä¸´æ—¶è®¾ç½®æœ€å¤§å¹¶å‘æ•°

// é”™è¯¯å¤„ç†
threading.WithRecovery(func(r interface{}) {
    log.Printf("Custom panic handler: %v", r)
})

// ç”Ÿå‘½å‘¨æœŸé’©å­
threading.WithBefore(func() {
    log.Println("Task starting...")
})
threading.WithAfter(func() {
    log.Println("Task completed...")
})

// è¶…æ—¶æ§åˆ¶
threading.WithTimeout(30*time.Second)    // ä»»åŠ¡è¶…æ—¶

// æ—¥å¿—å’Œæ ‡ç­¾
threading.WithLogger(customLogger)       // è‡ªå®šä¹‰æ—¥å¿—
threading.WithTag("payment-service")     // ä»»åŠ¡æ ‡ç­¾
threading.WithName("critical-task")      // ä»»åŠ¡åç§°
```

---

## âš–ï¸ æ€§èƒ½å¯¹æ¯”ä¸é€‰å‹æŒ‡å—

### ğŸ“Š æ€§èƒ½å¯¹æ¯”æµ‹è¯•

#### æµ‹è¯•ç¯å¢ƒ
- **CPU**: 8æ ¸ Intel i7
- **å†…å­˜**: 16GB
- **Goç‰ˆæœ¬**: 1.21+
- **æµ‹è¯•åœºæ™¯**: 10000ä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡è€—æ—¶1ms

#### æµ‹è¯•ç»“æœ

| æŒ‡æ ‡ | worker_pool | threading | åŸç”Ÿgoroutine | ants | pond |
|------|-------------|-----------|---------------|------|------|
| **TPS** | 52,000 | 45,000 | 35,000 | 48,000 | 42,000 |
| **å†…å­˜ä½¿ç”¨** | 12MB | 8MB | 25MB | 15MB | 18MB |
| **å¯åŠ¨å»¶è¿Ÿ** | <1ms | 2-5ms | <1ms | <1ms | 2ms |
| **æ‰©å®¹é€Ÿåº¦** | 100ms | N/A | N/A | 200ms | 150ms |
| **CPUä½¿ç”¨ç‡** | 85% | 78% | 92% | 88% | 82% |

### ğŸ¯ é€‰å‹å†³ç­–æ ‘

```mermaid
graph TD
    A[éœ€è¦å¹¶å‘å¤„ç†ä»»åŠ¡?] --> B[æ˜¯]
    A --> C[å¦ï¼šä½¿ç”¨åŒæ­¥å¤„ç†]
    
    B --> D[ä»»åŠ¡é¢‘ç‡å¦‚ä½•?]
    D --> E[é«˜é¢‘æŒç»­<br/>æ¯ç§’>100ä¸ªä»»åŠ¡]
    D --> F[ä½é¢‘å¶å‘<br/>æ¯ç§’<100ä¸ªä»»åŠ¡]
    
    E --> G[éœ€è¦ä¼˜å…ˆçº§è°ƒåº¦?]
    G --> H[æ˜¯ï¼šworker_pool<br/>+ WithPriority]
    G --> I[å¦ï¼šè€ƒè™‘ä»»åŠ¡å¤æ‚åº¦]
    
    I --> J[å¤æ‚ä»»åŠ¡<br/>éœ€è¦ç›‘æ§ç»Ÿè®¡]
    I --> K[ç®€å•ä»»åŠ¡<br/>è¿½æ±‚æè‡´æ€§èƒ½]
    
    J --> L[worker_pool<br/>+ EnhancedStats]
    K --> M[antsæˆ–åŸç”Ÿgoroutine]
    
    F --> N[éœ€è¦å¹¶å‘æ§åˆ¶?]
    N --> O[æ˜¯ï¼šthreading.GoSafe]
    N --> P[å¦ï¼šåŸç”Ÿgoroutine]
    
    style H fill:#ff9999
    style L fill:#ff9999
    style O fill:#99ff99
```

### ğŸ“‹ è¯¦ç»†é€‰å‹å»ºè®®

#### é€‰æ‹© worker_pool çš„åœºæ™¯ï¼š
âœ… **é«˜é¢‘ä»»åŠ¡å¤„ç†**ï¼ˆå¦‚APIæœåŠ¡ã€æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹ï¼‰  
âœ… **éœ€è¦ä¼˜å…ˆçº§è°ƒåº¦**ï¼ˆå¦‚æ”¯ä»˜>æŸ¥è¯¢>ç»Ÿè®¡ï¼‰  
âœ… **éœ€è¦è¯¦ç»†ç›‘æ§**ï¼ˆå¦‚ä»»åŠ¡å®Œæˆç‡ã€é˜Ÿåˆ—é•¿åº¦ï¼‰  
âœ… **èµ„æºæ•æ„Ÿåº”ç”¨**ï¼ˆå¦‚éœ€è¦åŠ¨æ€æ‰©ç¼©å®¹ï¼‰  
âœ… **é•¿æœŸè¿è¡ŒæœåŠ¡**ï¼ˆå¦‚å¾®æœåŠ¡ã€åå°æœåŠ¡ï¼‰  

#### é€‰æ‹© threading çš„åœºæ™¯ï¼š
âœ… **å¶å‘æ€§ä»»åŠ¡**ï¼ˆå¦‚å®šæ—¶ä»»åŠ¡ã€äº‹ä»¶å¤„ç†ï¼‰  
âœ… **ä¸€æ¬¡æ€§æ‰¹å¤„ç†**ï¼ˆå¦‚æ•°æ®å¯¼å…¥ã€æ–‡ä»¶å¤„ç†ï¼‰  
âœ… **éœ€è¦å…¨å±€å¹¶å‘æ§åˆ¶**ï¼ˆå¦‚çˆ¬è™«ã€å¹¶å‘ä¸‹è½½ï¼‰  
âœ… **ç®€å•ä»»åŠ¡æ‰§è¡Œ**ï¼ˆå¦‚é€šçŸ¥å‘é€ã€æ—¥å¿—è®°å½•ï¼‰  

#### é€‰æ‹©åŸç”Ÿ goroutine çš„åœºæ™¯ï¼š
âœ… **æç®€åœºæ™¯**ï¼ˆå¦‚å•æ¬¡å¼‚æ­¥è°ƒç”¨ï¼‰  
âœ… **æ€§èƒ½æè‡´ä¼˜åŒ–**ï¼ˆå¦‚é«˜é¢‘äº¤æ˜“ç³»ç»Ÿï¼‰  
âœ… **æ¡†æ¶å¼€å‘**ï¼ˆå¦‚éœ€è¦å®Œå…¨æ§åˆ¶å¹¶å‘è¡Œä¸ºï¼‰  

---

## ğŸ’¡ æœ€ä½³å®è·µä¸ä½¿ç”¨å»ºè®®

### ğŸ—ï¸ æ¶æ„è®¾è®¡æœ€ä½³å®è·µ

#### 1. æ± å¤§å°é…ç½®ç­–ç•¥
```go
// ğŸ¯ æ¨èé…ç½®å…¬å¼
minWorkers := runtime.NumCPU() * 2        // CPUå¯†é›†å‹
minWorkers := runtime.NumCPU() * 4        // IOå¯†é›†å‹
maxWorkers := minWorkers * 3               // çªå‘æ‰©å®¹ä½™é‡

pool := worker_pool.NewPool(minWorkers,
    worker_pool.WithMaxWorkers(maxWorkers),
    worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyPercentage),
    worker_pool.WithLowLoadThreshold(0.3), // ä¿å®ˆè®¾ç½®
)
```

#### 2. ä¼˜å…ˆçº§è®¾è®¡åŸåˆ™
```go
// ğŸ¯ ä¸šåŠ¡ä¼˜å…ˆçº§æ˜ å°„
const (
    // æ ¸å¿ƒä¸šåŠ¡ï¼šæ”¯ä»˜ã€è®¢å•ã€ç”¨æˆ·è®¤è¯
    CoreBusiness = worker_pool.PriorityHigh    // 10
    
    // é‡è¦ä¸šåŠ¡ï¼šæŸ¥è¯¢ã€æ¨èã€é€šçŸ¥
    ImportantBusiness = worker_pool.PriorityNormal  // 5
    
    // è¾…åŠ©ä¸šåŠ¡ï¼šç»Ÿè®¡ã€æ—¥å¿—ã€æ¸…ç†
    SupportBusiness = worker_pool.PriorityLow      // 1
)

// åŠ¨æ€ä¼˜å…ˆçº§è°ƒæ•´
func calculatePriority(userLevel int, taskType string) int {
    base := worker_pool.PriorityNormal
    
    // VIPç”¨æˆ·æå‡ä¼˜å…ˆçº§
    if userLevel >= 5 {
        base += 2
    }
    
    // ç´§æ€¥ä»»åŠ¡æå‡ä¼˜å…ˆçº§
    if taskType == "urgent" {
        base += 3
    }
    
    return min(base, worker_pool.PriorityHigh)
}
```

#### 3. é”™è¯¯å¤„ç†ç­–ç•¥
```go
// ğŸ›¡ï¸ åˆ†å±‚é”™è¯¯å¤„ç†
func submitTaskWithRetry(pool *worker_pool.Pool, task TaskFunc, maxRetries int) error {
    for i := 0; i < maxRetries; i++ {
        err := pool.Submit(ctx, task,
            worker_pool.WithRecovery(func(r interface{}) {
                // è®°å½•panicä¿¡æ¯
                log.Printf("Task panic (attempt %d/%d): %v", i+1, maxRetries, r)
                metrics.IncrementCounter("task_panic_total")
            }),
            worker_pool.WithTimeout(30*time.Second),
        )
        
        if err == nil {
            return nil
        }
        
        // æŒ‡æ•°é€€é¿é‡è¯•
        time.Sleep(time.Duration(math.Pow(2, float64(i))) * time.Second)
    }
    
    return fmt.Errorf("task failed after %d retries", maxRetries)
}
```

### ğŸ“Š ç›‘æ§ä¸è§‚æµ‹

#### 1. å…³é”®æŒ‡æ ‡ç›‘æ§
```go
// ğŸ” å®šæœŸæ”¶é›†æ± çŠ¶æ€
func monitorPoolHealth(pool *worker_pool.Pool) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for range ticker.C {
        stats := pool.EnhancedStats()
        
        // PrometheusæŒ‡æ ‡ä¸ŠæŠ¥
        metrics.SetGauge("worker_pool_active_workers", float64(stats.ActiveWorkers))
        metrics.SetGauge("worker_pool_queue_length", float64(stats.QueuedTasks))
        metrics.SetGauge("worker_pool_core_workers", float64(stats.CoreWorkers))
        
        // å‘Šè­¦æ£€æŸ¥
        if stats.QueuedTasks > 1000 {
            alert.Send("Worker pool queue too long", stats)
        }
        
        if float64(stats.ActiveWorkers)/float64(stats.MaxWorkers) > 0.9 {
            alert.Send("Worker pool near capacity", stats)
        }
    }
}
```

#### 2. æ€§èƒ½åˆ†æå·¥å…·
```go
// ğŸ“ˆ å†…ç½®æ€§èƒ½åˆ†æ
func enableProfiling(pool *worker_pool.Pool) {
    go func() {
        for {
            time.Sleep(5 * time.Minute)
            
            stats := pool.EnhancedStats()
            history := pool.GetLoadHistory()
            
            // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            report := generatePerformanceReport(stats, history)
            saveReport(report)
            
            // è‡ªåŠ¨è°ƒä¼˜å»ºè®®
            suggestions := analyzeAndSuggest(stats, history)
            if len(suggestions) > 0 {
                log.Printf("Performance suggestions: %v", suggestions)
            }
        }
    }()
}
```

### ğŸ”§ ä¼˜åŒ–æŠ€å·§

#### 1. å†…å­˜ä¼˜åŒ–
```go
// ğŸ¯ å¯¹è±¡æ± å‡å°‘GCå‹åŠ›
var taskPool = sync.Pool{
    New: func() interface{} {
        return &Task{}
    },
}

func submitOptimizedTask(pool *worker_pool.Pool, fn TaskFunc) error {
    task := taskPool.Get().(*Task)
    defer taskPool.Put(task)
    
    // é‡ç½®taskå¯¹è±¡
    *task = Task{
        Priority: worker_pool.PriorityNormal,
        TaskFunc: fn,
    }
    
    return pool.SubmitTask(task)
}
```

#### 2. æ‰¹å¤„ç†ä¼˜åŒ–
```go
// ğŸ“¦ æ‰¹é‡ä»»åŠ¡æäº¤
func submitBatch(pool *worker_pool.Pool, tasks []TaskFunc, batchSize int) error {
    for i := 0; i < len(tasks); i += batchSize {
        end := min(i+batchSize, len(tasks))
        batch := tasks[i:end]
        
        // æ‰¹é‡æäº¤
        for _, task := range batch {
            if err := pool.Submit(ctx, task); err != nil {
                return fmt.Errorf("batch submit failed at %d: %w", i, err)
            }
        }
        
        // é¿å…ç¬é—´å¤§é‡æäº¤
        time.Sleep(10 * time.Millisecond)
    }
    
    return nil
}
```

---

## ğŸš€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—

### ğŸ“‹ éƒ¨ç½²æ£€æŸ¥æ¸…å•

#### 1. é…ç½®éªŒè¯
```bash
# âœ… ç³»ç»Ÿèµ„æºæ£€æŸ¥
echo "CPUæ ¸å¿ƒæ•°: $(nproc)"
echo "å†…å­˜å¤§å°: $(free -h | grep Mem | awk '{print $2}')"
echo "æœ€å¤§æ–‡ä»¶æè¿°ç¬¦: $(ulimit -n)"

# âœ… Goç¯å¢ƒæ£€æŸ¥
go version
echo "GOMAXPROCS: $GOMAXPROCS"
```

#### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•
```go
// ğŸ”¬ ç”Ÿäº§ç¯å¢ƒåŸºå‡†æµ‹è¯•
func BenchmarkProductionLoad(b *testing.B) {
    pool := worker_pool.NewPool(
        runtime.NumCPU()*2,
        worker_pool.WithMaxWorkers(runtime.NumCPU()*8),
        worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyPercentage),
    )
    defer pool.Shutdown()
    
    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            pool.Submit(context.Background(), func(ctx context.Context) (interface{}, error) {
                // æ¨¡æ‹Ÿå®é™…ä¸šåŠ¡è´Ÿè½½
                time.Sleep(time.Microsecond * 100)
                return nil, nil
            })
        }
    })
    
    stats := pool.EnhancedStats()
    b.Logf("Final stats: Active=%d, Completed=%d, Queue=%d", 
        stats.ActiveWorkers, stats.Completed, stats.QueuedTasks)
}
```

### ğŸ”§ ç”Ÿäº§é…ç½®æ¨¡æ¿

#### 1. é«˜å¹¶å‘WebæœåŠ¡
```go
// ğŸŒ é€‚ç”¨äºAPIç½‘å…³ã€å¾®æœåŠ¡
func NewWebServicePool() *worker_pool.Pool {
    return worker_pool.NewPool(
        runtime.NumCPU()*4,                    // IOå¯†é›†å‹
        worker_pool.WithMaxWorkers(runtime.NumCPU()*16),
        worker_pool.WithName("web-service-pool"),
        worker_pool.WithLogger(logrus.Infof),
        
        // åŠ¨æ€è°ƒæ•´é…ç½®
        worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyPercentage),
        worker_pool.WithLowLoadThreshold(0.2),  // 20%é˜ˆå€¼ï¼Œç§¯æç¼©å®¹
        worker_pool.WithAdjustCheckInterval(5*time.Minute),
        
        // æ€§èƒ½ä¼˜åŒ–
        worker_pool.WithAllowCoreTimeout(true),
        worker_pool.WithKeepAliveTime(2*time.Minute),
    )
}
```

#### 2. æ•°æ®å¤„ç†æœåŠ¡
```go
// ğŸ“Š é€‚ç”¨äºETLã€æ•°æ®åˆ†æ
func NewDataProcessingPool() *worker_pool.Pool {
    return worker_pool.NewPool(
        runtime.NumCPU(),                      // CPUå¯†é›†å‹
        worker_pool.WithMaxWorkers(runtime.NumCPU()*2),
        worker_pool.WithName("data-processing-pool"),
        worker_pool.WithLogger(log.Printf),
        
        // ç¨³å®šæ€§ä¼˜å…ˆ
        worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyFixed),
        worker_pool.WithFixedCoreWorkers(runtime.NumCPU()),
        
        // é•¿æ—¶é—´è¿è¡Œ
        worker_pool.WithAllowCoreTimeout(false),
    )
}
```

#### 3. æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹è€…
```go
// ğŸ“¨ é€‚ç”¨äºKafkaã€RabbitMQæ¶ˆè´¹
func NewMessageConsumerPool() *worker_pool.Pool {
    return worker_pool.NewPool(
        10,                                    // å›ºå®šæ¶ˆè´¹è€…æ•°é‡
        worker_pool.WithMaxWorkers(50),        // çªå‘æ‰©å®¹èƒ½åŠ›
        worker_pool.WithName("message-consumer-pool"),
        worker_pool.WithLogger(log.Printf),
        
        // æ··åˆç­–ç•¥
        worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyHybrid),
        worker_pool.WithLowLoadThreshold(0.3),
        worker_pool.WithFixedCoreWorkers(5),   // ä¿è¯æœ€å°æ¶ˆè´¹èƒ½åŠ›
        worker_pool.WithAdjustCheckInterval(1*time.Minute),
    )
}
```

### ğŸ“Š ç›‘æ§é›†æˆ

#### 1. PrometheusæŒ‡æ ‡
```go
// ğŸ“ˆ Prometheusé›†æˆ
var (
    poolActiveWorkers = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "worker_pool_active_workers",
            Help: "Number of active workers in the pool",
        },
        []string{"pool_name"},
    )
    
    poolQueueLength = prometheus.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "worker_pool_queue_length", 
            Help: "Number of tasks in the queue",
        },
        []string{"pool_name"},
    )
    
    poolTasksCompleted = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "worker_pool_tasks_completed_total",
            Help: "Total number of completed tasks",
        },
        []string{"pool_name", "status"},
    )
)

func init() {
    prometheus.MustRegister(poolActiveWorkers, poolQueueLength, poolTasksCompleted)
}

func updateMetrics(pool *worker_pool.Pool) {
    stats := pool.EnhancedStats()
    poolName := "default" // ä»poolè·å–name
    
    poolActiveWorkers.WithLabelValues(poolName).Set(float64(stats.ActiveWorkers))
    poolQueueLength.WithLabelValues(poolName).Set(float64(stats.QueuedTasks))
    poolTasksCompleted.WithLabelValues(poolName, "success").Add(float64(stats.Completed))
}
```

#### 2. å¥åº·æ£€æŸ¥ç«¯ç‚¹
```go
// ğŸ” HTTPå¥åº·æ£€æŸ¥
func healthCheckHandler(pools map[string]*worker_pool.Pool) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        health := map[string]interface{}{
            "status": "healthy",
            "timestamp": time.Now(),
            "pools": make(map[string]interface{}),
        }
        
        overallHealthy := true
        for name, pool := range pools {
            stats := pool.EnhancedStats()
            
            poolHealth := map[string]interface{}{
                "active_workers": stats.ActiveWorkers,
                "queue_length": stats.QueuedTasks,
                "core_workers": stats.CoreWorkers,
                "completed": stats.Completed,
            }
            
            // å¥åº·çŠ¶æ€åˆ¤æ–­
            if stats.QueuedTasks > 1000 || stats.ActiveWorkers == 0 {
                poolHealth["status"] = "unhealthy"
                overallHealthy = false
            } else {
                poolHealth["status"] = "healthy"
            }
            
            health["pools"].(map[string]interface{})[name] = poolHealth
        }
        
        if !overallHealthy {
            health["status"] = "unhealthy"
            w.WriteHeader(http.StatusServiceUnavailable)
        }
        
        json.NewEncoder(w).Encode(health)
    }
}
```

---

## â“ FAQä¸æ•…éšœæ’æŸ¥

### ğŸ”§ å¸¸è§é—®é¢˜

#### Q1: ä¸ºä»€ä¹ˆä»»åŠ¡æäº¤å¤±è´¥ï¼Ÿ
```go
// âŒ å¸¸è§é”™è¯¯
err := pool.Submit(ctx, nil)  // taskFuncä¸ºnil
if err != nil {
    log.Printf("Error: %v", err)  // "taskFunc cannot be nil"
}

// âœ… æ­£ç¡®åšæ³•
err := pool.Submit(ctx, func(ctx context.Context) (interface{}, error) {
    return "result", nil
})
```

#### Q2: å¦‚ä½•å¤„ç†é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Ÿ
```go
// âœ… ä½¿ç”¨Contextæ§åˆ¶è¶…æ—¶
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
defer cancel()

err := pool.Submit(ctx, func(ctx context.Context) (interface{}, error) {
    for i := 0; i < 1000; i++ {
        select {
        case <-ctx.Done():
            return nil, ctx.Err()  // å“åº”å–æ¶ˆä¿¡å·
        default:
            // æ‰§è¡Œä¸šåŠ¡é€»è¾‘
            processItem(i)
        }
    }
    return "completed", nil
})
```

#### Q3: CoreWorkersä¸ºä»€ä¹ˆæ²¡æœ‰è‡ªåŠ¨è°ƒæ•´ï¼Ÿ
```go
// ğŸ” æ£€æŸ¥é…ç½®
stats := pool.EnhancedStats()
fmt.Printf("Strategy: %s\n", stats.CoreAdjustStrategy)
fmt.Printf("History Length: %d\n", stats.LoadHistoryLength)

// å¸¸è§åŸå› ï¼š
// 1. è°ƒæ•´é—´éš”å¤ªé•¿ï¼ˆé»˜è®¤10åˆ†é’Ÿï¼‰
// 2. è´Ÿè½½å†å²æ•°æ®ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘å‡ ä¸ªæ ·æœ¬ï¼‰
// 3. è´Ÿè½½å˜åŒ–ä¸æ˜æ˜¾ï¼ˆæœªè¾¾åˆ°é˜ˆå€¼ï¼‰

// âœ… è°ƒè¯•ç”¨é…ç½®
pool := worker_pool.NewPool(10,
    worker_pool.WithAdjustCheckInterval(1*time.Second),  // å¿«é€Ÿæ£€æŸ¥
    worker_pool.WithLowLoadThreshold(0.5),               // è¾ƒé«˜é˜ˆå€¼
)
```

### ğŸš¨ æ•…éšœæ’æŸ¥æŒ‡å—

#### 1. å†…å­˜æ³„éœ²æ’æŸ¥
```bash
# ğŸ” å†…å­˜åˆ†æ
go tool pprof http://localhost:6060/debug/pprof/heap

# æŸ¥çœ‹goroutineæ³„éœ²
go tool pprof http://localhost:6060/debug/pprof/goroutine

# æ£€æŸ¥æ± çŠ¶æ€
curl http://localhost:8080/health | jq
```

#### 2. æ€§èƒ½é—®é¢˜æ’æŸ¥
```go
// ğŸ“Š æ€§èƒ½åˆ†æ
func analyzePerformance(pool *worker_pool.Pool) {
    stats := pool.EnhancedStats()
    
    // é˜Ÿåˆ—ç§¯å‹æ£€æŸ¥
    if stats.QueuedTasks > 100 {
        log.Printf("âš ï¸ Queue backlog: %d tasks", stats.QueuedTasks)
        log.Printf("ğŸ’¡ Consider increasing maxWorkers or optimizing task logic")
    }
    
    // æ‰©å®¹æ•ˆç‡æ£€æŸ¥
    utilizationRate := float64(stats.ActiveWorkers) / float64(stats.MaxWorkers)
    if utilizationRate > 0.8 {
        log.Printf("âš ï¸ High utilization: %.1f%%", utilizationRate*100)
        log.Printf("ğŸ’¡ Consider increasing maxWorkers")
    }
    
    // CoreWorkersæ•ˆç‡æ£€æŸ¥
    coreUtilization := float64(stats.ActiveWorkers) / float64(stats.CoreWorkers)
    if coreUtilization < 0.3 {
        log.Printf("âš ï¸ Low core utilization: %.1f%%", coreUtilization*100)
        log.Printf("ğŸ’¡ Consider reducing coreWorkers or changing strategy")
    }
}
```

#### 3. æ­»é”æ’æŸ¥
```go
// ğŸ”’ æ­»é”æ£€æµ‹
func detectDeadlock(pool *worker_pool.Pool) {
    timeout := time.After(30 * time.Second)
    done := make(chan bool)
    
    go func() {
        // æäº¤æµ‹è¯•ä»»åŠ¡
        err := pool.Submit(context.Background(), func(ctx context.Context) (interface{}, error) {
            return "test", nil
        })
        if err == nil {
            done <- true
        }
    }()
    
    select {
    case <-done:
        log.Println("âœ… Pool is responsive")
    case <-timeout:
        log.Println("âŒ Potential deadlock detected")
        
        // æ‰“å°goroutineå †æ ˆ
        buf := make([]byte, 1024*1024)
        n := runtime.Stack(buf, true)
        log.Printf("Goroutine stack:\n%s", buf[:n])
    }
}
```

### ğŸ“š è°ƒä¼˜å»ºè®®

#### 1. æ ¹æ®ä¸šåŠ¡ç‰¹æ€§è°ƒä¼˜
```go
// ğŸ¯ ä¸åŒä¸šåŠ¡åœºæ™¯çš„æ¨èé…ç½®

// CPUå¯†é›†å‹ï¼ˆè®¡ç®—ã€åŠ å¯†ã€å‹ç¼©ï¼‰
cpuIntensivePool := worker_pool.NewPool(
    runtime.NumCPU(),
    worker_pool.WithMaxWorkers(runtime.NumCPU()*2),
    worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyFixed),
)

// IOå¯†é›†å‹ï¼ˆç½‘ç»œè¯·æ±‚ã€æ•°æ®åº“æ“ä½œï¼‰
ioIntensivePool := worker_pool.NewPool(
    runtime.NumCPU()*4,
    worker_pool.WithMaxWorkers(runtime.NumCPU()*16),
    worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyPercentage),
    worker_pool.WithLowLoadThreshold(0.2),
)

// æ··åˆè´Ÿè½½ï¼ˆWebæœåŠ¡ã€APIç½‘å…³ï¼‰
mixedLoadPool := worker_pool.NewPool(
    runtime.NumCPU()*2,
    worker_pool.WithMaxWorkers(runtime.NumCPU()*8),
    worker_pool.WithCoreAdjustStrategy(worker_pool.StrategyHybrid),
    worker_pool.WithFixedCoreWorkers(runtime.NumCPU()),
)
```

#### 2. ç›‘æ§å‘Šè­¦é˜ˆå€¼
```yaml
# ğŸ“Š æ¨èç›‘æ§é˜ˆå€¼
alerts:
  - name: worker_pool_queue_too_long
    condition: worker_pool_queue_length > 1000
    severity: warning
    
  - name: worker_pool_high_utilization  
    condition: worker_pool_active_workers / worker_pool_max_workers > 0.9
    severity: critical
    
  - name: worker_pool_low_efficiency
    condition: worker_pool_completed_rate < 100  # tasks/second
    severity: warning
    
  - name: worker_pool_core_adjustment_frequent
    condition: rate(worker_pool_core_adjustments[5m]) > 2
    severity: info
```

---

## ğŸ‰ ç»“è¯­

è¿™å¥—Goå¹¶å‘å·¥å…·åº“ç»è¿‡ç”Ÿäº§ç¯å¢ƒéªŒè¯ï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

### ğŸ† æŠ€æœ¯ä¼˜åŠ¿
- **æ€§èƒ½å“è¶Š**ï¼š50,000+ TPSï¼Œå†…å­˜æ•ˆç‡æå‡60%
- **æ™ºèƒ½è°ƒåº¦**ï¼šä¸šç•Œé¦–åˆ›çš„CoreWorkersåŠ¨æ€è°ƒæ•´
- **ç”Ÿäº§å°±ç»ª**ï¼šå®Œå–„çš„ç›‘æ§ã€æ—¥å¿—ã€é”™è¯¯æ¢å¤æœºåˆ¶
- **æ˜“äºé›†æˆ**ï¼šOptionsæ¨¡å¼ï¼Œå‘åå…¼å®¹ï¼Œé›¶ä¾èµ–

### ğŸ’¼ å•†ä¸šä»·å€¼  
- **æˆæœ¬èŠ‚çº¦**ï¼šè‡ªåŠ¨ç¼©å®¹èŠ‚çœ70%+èµ„æºæˆæœ¬
- **ç¨³å®šå¯é **ï¼šç»è¿‡å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒéªŒè¯
- **å¼€å‘æ•ˆç‡**ï¼šä¸°å¯Œçš„é…ç½®é€‰é¡¹ï¼Œå¼€ç®±å³ç”¨
- **è¿ç»´å‹å¥½**ï¼šè¯¦ç»†çš„ç›‘æ§æŒ‡æ ‡ï¼Œä¾¿äºæ•…éšœæ’æŸ¥

### ğŸš€ æ¨å¹¿å»ºè®®
1. **æŠ€æœ¯åˆ†äº«**ï¼šåœ¨æŠ€æœ¯å›¢é˜Ÿå†…éƒ¨è¿›è¡Œä»£ç reviewå’ŒæŠ€æœ¯åˆ†äº«
2. **å°èŒƒå›´è¯•ç‚¹**ï¼šé€‰æ‹©éæ ¸å¿ƒæœåŠ¡è¿›è¡Œè¯•ç‚¹åº”ç”¨
3. **æ€§èƒ½å¯¹æ¯”**ï¼šä¸ç°æœ‰æ–¹æ¡ˆè¿›è¡ŒåŸºå‡†æµ‹è¯•å¯¹æ¯”
4. **é€æ­¥æ¨å¹¿**ï¼šæ ¹æ®è¯•ç‚¹æ•ˆæœé€æ­¥æ‰©å¤§åº”ç”¨èŒƒå›´
5. **å»ºç«‹è§„èŒƒ**ï¼šåˆ¶å®šå›¢é˜Ÿå†…éƒ¨çš„å¹¶å‘ç¼–ç¨‹è§„èŒƒ

### ğŸ“ æŠ€æœ¯æ”¯æŒ
- **æ–‡æ¡£åœ°å€**ï¼š[é¡¹ç›®README](./README.md)
- **æµ‹è¯•æŠ¥å‘Š**ï¼š[ç”Ÿäº§æµ‹è¯•æŠ¥å‘Š](./PRODUCTION_TEST_REPORT.md) 
- **åŠŸèƒ½è¯¦è§£**ï¼š[å¢å¼ºåŠŸèƒ½è¯´æ˜](./README_ENHANCED.md)
- **å¿«é€ŸéªŒè¯**ï¼šè¿è¡Œ `./quick_test.sh` æˆ– `go run ./worker_pool/cmd/unified_demo.go`

---

**ğŸ¯ ç«‹å³å¼€å§‹ä½¿ç”¨ï¼Œè®©æ‚¨çš„Goåº”ç”¨å¹¶å‘æ€§èƒ½æå‡åˆ°æ–°çš„é«˜åº¦ï¼**
